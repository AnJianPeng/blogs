---
title: "GFS"
date: 2024-02-01
---
# Distributed Storage System
Why hard?
Start for performance => Sharding data with thousands of machines => Fault (machine could fail, especially with many machiens) => Fault tolerance (Replication) => Inconsitency between replication => Stronger consistency with low performance

## Strong Consistency
### Bad Replication Design
Clients responsible for sending request towards replicas to update records => No way to enforce the order of requests because requests can arrive in different order due to network

# GFS
Since 2003, Big + Fast + Universal in Google + Sharding + Automatic Fault Recovery 
Single data center + Internal use + Big (GB/TB) sequential access
Compared to academic papers, GFS is specail in 1. Vast data in a big system with 100K+ machines 2. Performance > Consistency 3. Single master works fine

## Structure
**100+ client**
**Master server**
**100+ Chunk servers**

### Details in Master Server
Log, Checkpoint on disk
Log is efficient since the write is sequential
Checkpoint for faster recovery without going through all the logs after each crash

| Metadata | Fields | Volatility |
| --- | --- | --- |
| file name | array of CH(chunk handles) | Non-Volatile |
| chunk handle | array of CS(chunk servers) | Volatile |
| | version # | Non-Volatile |
| | primay chunk | Volatile |
| | lease expiration | Volatile |

## Reads in GFS
```
string Read(fileName, offset)
```
1. client (fileName, offset)=> M
2. Master (CH, array of CS)=> Client
    * Clients cache the response
3. Client (Data request)=> CS

## Writes in GFS
```
void Append(fileName, data)
```

### No Primary
1. Find up-to-date replicas
2. Pick Primary, Secondary
3. Increment V#
4. Master (V#)=> Primary, Secondary
    * Primary with lease expiration
5. Master persists V#

We can't rely on CS's largest V# to restore Master's V#, because not all CS are necessarily available when Master reboots.

V# only happens when there is no primary.

1. Primary picks off
2. Primary (told to write off)=> All Secondary
3. IF
    * all replicas succeed, Primary ("Yes")=> C
    * Otherwise, Primary ("No")=> C

Primary knows all Secondary so that it can tell them to write? How the replication happens between replicas?

### Unhappy Path
Consistency Issue
    * Different replicas could store different data when failures of append happens.
    * Rely on the application logic for strong consistency.
It is single master.
    * Run of RAM in Master since it needs to hold metadata for all files. 
    * Throughput limitation on the number of connected clients to Master
Manual repair is needed when master machine permanently failed.