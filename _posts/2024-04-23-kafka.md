---
title: "Kafka Design Introduction"
date: 2024-04-27
---

# Introduction
Kafka is a distributed event streaming platform to capture, store, process, and route events from various sources, like databases, sensors, mobile devices, cloud services, and software applications. It has the following properties:
* High throughput
* Large data backlogs
* Low latency
* Partition
* Fault Tolerance (Replication)

Kafka can connect to external systems (for data import/export) via Kafka Connect, and provides the Kafka Streams libraries for stream processing applications.

# Components
You can see the following components in Kafka:
| Name | Description | Example |
| --- | --- | --- |
| Event | Data that Kafka stores and processes | * Key: "Alice" <br> * Value: "Mad a pyament of $200 to Bob" <br> * Timestamp: "Jun. 25, 2020 at 2:06pm" |
| Topic | Events are organized in topics in Kafka | |
| Producer | Client applications that write data to Kafka topics | A Java or Scala application calls Kafka Write APIs |
| Consumer | Client applications that read data from Kafka topics | A Java or Scala application calls Kafka Read APIs |
| Broker | Servers in a Kafka that store data | |

# Design
## Persistence
See the [link](https://kafka.apache.org/documentation/#persistence)

## Efficiency
Kafka is optimized for efficiency to limit small I/O operations and excessive byte copying.

### Limit small I/O operations
Batching - Amortize the network roundtrip cost by grouping messages in network requests
**Pros** - Larger network packets, larger sequential disk operations, contiguous memory blocks, smooth bursts of messages

### Limit excessive byte copying
Sendfile - avoid byte copying; pagecache -> socket

Batch Compression - Producers compress a batch of messages -> Brokers validate the batch -> Brokers persist the batch in compression form -> Consumers get compressed batches -> Consumer decompress

## Producer
Load balancing - Any Kafka nodes can answer metadata about the leader of topics; Client controls which partition to publish messages; Support semantic partitioning (partition a topic by a key)

Asynchronous send - Accumulate messages before sending batches out asynchronously

## Consumer
In Kafka, data is pushed to the broker from the producer and pulled from the broker by the consumer.

**Pull-based system**

Pros - 1. Consumer controls its own pace, no overwhelming 2. Allow aggressive batching of data sent to the consumer

Cons - 1. Busy waiting (long poll mitigates it)

**Consumer Position**

Consumer position is stored in Brokers (Not used by Kafka)

Cons - 1. Complicated with broker management because message/acknowledgment could be lost/unordered in network

Consumer position is stored in Clients (Used by Kafka)

Pros - 1. Small position metadata for each consumer group

**Offline Data Load**

Scalable persistence in Kafka allows bulk-load data into an offline system for further analysis, like Hadoop or a relational data warehouse.

## Message Delivery Semantics
| Semantic Type | Description | Implementation |
| --- | --- | --- |
| At most once | Messages may be lost but are never redelivered | Failed messages may not be processed
| At least once | Messages are never lost but may be redelivered | Retry the failed messages could cause redelivery
| Exactly once | Each message is delivered once and only once | Idempotent message redelivery with unique ID check

After 0.11.0.0, Kafka supports transaction-like semantics when sending messages to multiple topics. With the feature, Kafka supports exactly-once processing as discussed below. Users can ease guarantees based on their needs.

### How to achieve exactly once semantic?
**Scenario 1 - Read from a Kafka topic-A and write response to another topic-B**

The consumer position in topic-A is stored as a message in topic-C. Combining the write of consumer position and response into a Kafka transaction under "read_commited" isolation level.

**Scenario 2 - Read from a Kafka topic-A and write response to an external system**

1. Store the consumer position in topic-A in the external system and use the transactional semantics there.
2. Two-phase commit

## Log Compaction
Log compaction ensures that Kafka will always retain the last known value for each message key within the log of data for a single topic partition. In the following example, *bill@gmail.com* will be the value of the key *123*.
```
123 => bill@microsoft.com

123 => bill@gatesfoundation.org

123 => bill@gmail.com
```
This feature guarantees that Kafka keeps the final value for every key. Downstream consumers can restore the state from the topic without retaining a complete log of all changes.

## Replication
| Node Type | Description | Health condition | 
| --- | --- | --- |
| Controller | a special node in Kafka for managing the registration of brokers | |
| Leaders | * All writes of a partition come to its leader <br> * Reads of the partition can go to its leader or followers | Timely heartbeats towards the controller |
| Followers | Reads of the partition can go to its leader or followers | 1. Timely heartbeats towards the controller <br> 2. Followers' log should not fall "too far" behind the leader |

A message is considered committed when all replicas in the ISR for that partition have applied it to their log.

### Quorum & Majority Vote
> If you choose the number of acknowledgments required and the number of logs that must be compared to elect a leader such that there is guaranteed to be an overlap, then this is called a Quorum.

> A common approach to this tradeoff is to use a majority vote for both the commit decision and the leader election.

Pros - The majority vote approach is dependent on the fastest servers, benefiting the latency.

Cons - The majority vote approach doesn't tolerate many server failures. 2x replicas only tolerate a single server failure but 4x replicas cost more throughput and more disk space.

Observation - The majority vote approach is more common for key configuration storage but NOT data storage.

### Kafka's Way
1. A message is considered committed when all replicas in the ISR for that partition have applied it to their log. Because of this, any replica in the ISR is eligible to be elected leader.
2. Another important design distinction is that Kafka does not require that crashed nodes recover with all their data intact.  Our protocol for allowing a replica to rejoin the ISR ensures that before rejoining, it must fully re-sync again even if it lost unflushed data in its crash.

Pros - With this ISR model and *f+1* replicas, a Kafka topic can tolerate *f* failures without losing committed messages.

Cons - Sacrifying latency since all replicas need to apply the changes.

# Reference
* [Kafka Design Documentation](https://kafka.apache.org/documentation/#design)


